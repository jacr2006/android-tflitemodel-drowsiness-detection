{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacr2006/android-tflitemodel-drowsiness-detection/blob/master/data_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltrga60yFZgF",
        "colab_type": "code",
        "outputId": "75f8cadf-f578-4468-8a9f-5cfa12ab3fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIvUhIfDKoZJ",
        "colab_type": "code",
        "outputId": "f08f8109-f33d-4b04-9903-d478bce68b1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ12Up6BWiPS",
        "colab_type": "code",
        "outputId": "441afc4d-d2c6-41db-8256-977af9063624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from tensorboardcolab import TensorBoardColab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i38dQ2YlEHyw",
        "colab_type": "code",
        "outputId": "81560d9f-4d85-466e-a128-3afc16356d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "N_LANDMARK = 68# numero de marcas faciales\n",
        "INPUT_SHAPE = (96, 96, 1)# ancho, alto y canales de la imagen\n",
        "OUTPUT_SIZE = N_LANDMARK*2# tamaño de la capa de salida, dos coordenadas por cada marca facial\n",
        "\n",
        "# lectura de los dataser previamente procesados\n",
        "PATH_DRIVE = '/content/drive/My Drive/Proyectos Nuevos/ML/multiclass_landmark_keras_cnn/'\n",
        "X = np.load(PATH_DRIVE + \"img_dataset.npy\")\n",
        "y = np.load(PATH_DRIVE + \"pts_dataset.npy\")\n",
        "print(y.shape)\n",
        "y = y.reshape(-1, OUTPUT_SIZE)\n",
        "\n",
        "# escalada de la data de entrada\n",
        "#m = np.mean(X)\n",
        "#X = (X-m)/255.0# normalizacion de los datos entre (-1,1)\n",
        "X = X/255.0#normalizacion de los datos entre (0,1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6666, 68, 2)\n",
            "(6666, 96, 96, 1)\n",
            "(6666, 136)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLzqWKZcjST6",
        "colab_type": "text"
      },
      "source": [
        "Visualizacion de la data normalizada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlIx-ob7AdFe",
        "colab_type": "code",
        "outputId": "87b85dfc-2cdd-4a25-e4fe-7d6310e08b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(X[100,:,:,0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15686275 0.1254902  0.10588235 ... 0.07843137 0.1372549  0.18039216]\n",
            " [0.16470588 0.11372549 0.11372549 ... 0.08235294 0.12156863 0.18039216]\n",
            " [0.14509804 0.10588235 0.12941176 ... 0.07843137 0.10588235 0.16470588]\n",
            " ...\n",
            " [0.78431373 0.17647059 0.21176471 ... 0.16862745 0.12156863 0.23137255]\n",
            " [0.80392157 0.20784314 0.23529412 ... 0.81176471 0.65098039 0.34901961]\n",
            " [0.83921569 0.25490196 0.23137255 ... 0.65490196 0.60784314 0.69411765]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqR4lZTIuTCd",
        "colab_type": "code",
        "outputId": "633ff744-83b0-429b-db88-e0fa357db6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(y[100,:])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  4.  27.   5.  38.   8.  51.   9.  63.  12.  74.  18.  82.  28.  91.\n",
            "  39.  99.  50. 100.  60.  98.  67.  91.  73.  84.  78.  74.  82.  64.\n",
            "  84.  53.  85.  41.  86.  29.  15.  19.  19.  10.  28.  10.  38.  13.\n",
            "  45.  17.  58.  16.  66.  14.  72.  11.  79.   9.  83.  16.  52.  25.\n",
            "  53.  34.  54.  43.  54.  52.  43.  59.  48.  60.  52.  61.  56.  60.\n",
            "  60.  58.  23.  26.  29.  23.  35.  23.  39.  29.  34.  30.  28.  30.\n",
            "  60.  29.  65.  24.  72.  23.  75.  27.  72.  30.  65.  30.  34.  69.\n",
            "  42.  69.  46.  69.  49.  70.  53.  69.  58.  70.  65.  69.  57.  76.\n",
            "  52.  79.  48.  79.  45.  78.  41.  76.  37.  69.  45.  72.  49.  73.\n",
            "  53.  73.  62.  71.  53.  73.  49.  73.  45.  72.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zBc0LDjXrX",
        "colab_type": "text"
      },
      "source": [
        "Estructura de la red neuronal (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLWcCX0lsvGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.core import Activation, Dense\n",
        "from keras.layers import Flatten, Input, Convolution2D, add, Dropout, MaxPool2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=INPUT_SHAPE))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(OUTPUT_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htqYhJWStOjf",
        "colab_type": "code",
        "outputId": "1921ce82-2727-4a72-9b86-dd3dcdbd07ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "\n",
        "NUM_EPOCHS = 100# numero de epocas de entrenamiento\n",
        "INIT_LR = 0.001# coeficiente de aprendizaje inicial\n",
        "BS = 256# se inicio el entrenamiento con un tamaño de 32 y se aumento hasta lograr la convergencia\n",
        "\n",
        "# entrenar una CNN para detectar marcas faciales es distinto de predecir clases (binaria o multiclase)\n",
        "# en vez de obtener una distribucion de clases usando una funcion de perdida como \"entropy loss\" que mide la capacidad de clasificacion,\n",
        "# se debe usar una fucnion de perdida para regresion, la cual compara directamente el valor inferido con el real \n",
        "\n",
        "#opt = SGD(lr=INIT_LR, momentum=0.9)# Gradiente descendete estoscastico como metodo de optimizacion\n",
        "opt = Adam(lr=INIT_LR, decay=1e-3 / 200)\n",
        "\n",
        "# compilacion del modelo\n",
        "model.compile(loss='mean_squared_error', optimizer=opt, metrics=[\"mae\"])\n",
        "\n",
        "tbc=TensorBoardColab()\n",
        "callbacks_list = [TensorBoardColabCallback(tbc)]\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://b783080e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3SWuBV0yBeX",
        "colab_type": "code",
        "outputId": "aac0d8f8-d075-46ff-9647-b841640ad870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "H = model.fit(\n",
        "    X, y, batch_size=BS, \n",
        "    epochs=NUM_EPOCHS, shuffle=True,\n",
        "    verbose=1, \n",
        "    validation_split = 0.2,\n",
        "    callbacks=callbacks_list)\n",
        "\n",
        "model.save(PATH_DRIVE+'models/model2.h5')\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5332 samples, validate on 1334 samples\n",
            "Epoch 1/100\n",
            "5332/5332 [==============================] - 6s 1ms/step - loss: 28270.4508 - mean_absolute_error: 16.9843 - val_loss: 719.0173 - val_mean_absolute_error: 11.5242\n",
            "Epoch 2/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 22589.1363 - mean_absolute_error: 16.9909 - val_loss: 685.9101 - val_mean_absolute_error: 10.7773\n",
            "Epoch 3/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 16263.7122 - mean_absolute_error: 14.5716 - val_loss: 1234.7526 - val_mean_absolute_error: 11.3038\n",
            "Epoch 4/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 8981.5007 - mean_absolute_error: 13.3318 - val_loss: 887.2483 - val_mean_absolute_error: 10.8456\n",
            "Epoch 5/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 9856.4670 - mean_absolute_error: 13.1393 - val_loss: 5269.7010 - val_mean_absolute_error: 22.3118\n",
            "Epoch 6/100\n",
            "5332/5332 [==============================] - 4s 743us/step - loss: 15981.1576 - mean_absolute_error: 13.7918 - val_loss: 1176.6110 - val_mean_absolute_error: 11.7975\n",
            "Epoch 7/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 5052.6244 - mean_absolute_error: 10.6132 - val_loss: 948.0281 - val_mean_absolute_error: 10.4079\n",
            "Epoch 8/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 4724.8678 - mean_absolute_error: 10.6654 - val_loss: 1156.4107 - val_mean_absolute_error: 12.6625\n",
            "Epoch 9/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 21643.4000 - mean_absolute_error: 12.5930 - val_loss: 931.2338 - val_mean_absolute_error: 11.4998\n",
            "Epoch 10/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 7147.1825 - mean_absolute_error: 12.0352 - val_loss: 1419.6174 - val_mean_absolute_error: 13.3291\n",
            "Epoch 11/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 2037.4052 - mean_absolute_error: 9.9336 - val_loss: 1355.6701 - val_mean_absolute_error: 12.7083\n",
            "Epoch 12/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 2196.4895 - mean_absolute_error: 9.7470 - val_loss: 1464.6581 - val_mean_absolute_error: 13.4694\n",
            "Epoch 13/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1936.8784 - mean_absolute_error: 9.5693 - val_loss: 1504.8008 - val_mean_absolute_error: 13.5944\n",
            "Epoch 14/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 2891.4034 - mean_absolute_error: 9.9937 - val_loss: 1433.9756 - val_mean_absolute_error: 12.9968\n",
            "Epoch 15/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1986.2695 - mean_absolute_error: 9.6744 - val_loss: 1410.7721 - val_mean_absolute_error: 12.7872\n",
            "Epoch 16/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 2232.9208 - mean_absolute_error: 9.4558 - val_loss: 1464.7050 - val_mean_absolute_error: 12.9263\n",
            "Epoch 17/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 1929.2463 - mean_absolute_error: 9.5363 - val_loss: 1429.2088 - val_mean_absolute_error: 12.7339\n",
            "Epoch 18/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 2688.6054 - mean_absolute_error: 9.6273 - val_loss: 1376.8542 - val_mean_absolute_error: 13.1254\n",
            "Epoch 19/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 2543.8117 - mean_absolute_error: 9.4235 - val_loss: 1492.5041 - val_mean_absolute_error: 13.3541\n",
            "Epoch 20/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 6078.1240 - mean_absolute_error: 10.2439 - val_loss: 1403.5278 - val_mean_absolute_error: 12.3479\n",
            "Epoch 21/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 6807.8092 - mean_absolute_error: 10.0919 - val_loss: 1655.0907 - val_mean_absolute_error: 14.5658\n",
            "Epoch 22/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 11125.3349 - mean_absolute_error: 10.7132 - val_loss: 2451.5694 - val_mean_absolute_error: 16.5255\n",
            "Epoch 23/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 3027.2478 - mean_absolute_error: 9.7019 - val_loss: 3541.3384 - val_mean_absolute_error: 20.8624\n",
            "Epoch 24/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 4291.1728 - mean_absolute_error: 9.7984 - val_loss: 2650.6513 - val_mean_absolute_error: 18.0248\n",
            "Epoch 25/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 5821.0427 - mean_absolute_error: 9.9601 - val_loss: 2176.7725 - val_mean_absolute_error: 16.4278\n",
            "Epoch 26/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 6893.9471 - mean_absolute_error: 10.8656 - val_loss: 16705.3328 - val_mean_absolute_error: 24.8598\n",
            "Epoch 27/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 3645.1238 - mean_absolute_error: 9.3808 - val_loss: 15323.4180 - val_mean_absolute_error: 17.3907\n",
            "Epoch 28/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 4302.1198 - mean_absolute_error: 9.6202 - val_loss: 1543.1342 - val_mean_absolute_error: 13.7418\n",
            "Epoch 29/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 2681.9811 - mean_absolute_error: 9.3738 - val_loss: 1597.6901 - val_mean_absolute_error: 13.7575\n",
            "Epoch 30/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 2124.9128 - mean_absolute_error: 9.2102 - val_loss: 1338.2312 - val_mean_absolute_error: 13.0580\n",
            "Epoch 31/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1648.7315 - mean_absolute_error: 9.0014 - val_loss: 1330.1512 - val_mean_absolute_error: 13.4079\n",
            "Epoch 32/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 4080.8217 - mean_absolute_error: 9.6484 - val_loss: 1345.8717 - val_mean_absolute_error: 13.1632\n",
            "Epoch 33/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1539.6166 - mean_absolute_error: 8.8754 - val_loss: 1493.7617 - val_mean_absolute_error: 13.7253\n",
            "Epoch 34/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1889.1052 - mean_absolute_error: 9.0547 - val_loss: 1306.3467 - val_mean_absolute_error: 12.7820\n",
            "Epoch 35/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1885.7242 - mean_absolute_error: 8.9275 - val_loss: 1417.8707 - val_mean_absolute_error: 13.4793\n",
            "Epoch 36/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 2142.9504 - mean_absolute_error: 9.1423 - val_loss: 1476.3872 - val_mean_absolute_error: 13.3983\n",
            "Epoch 37/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 1492.3007 - mean_absolute_error: 9.1752 - val_loss: 1324.9610 - val_mean_absolute_error: 13.2274\n",
            "Epoch 38/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 2542.8946 - mean_absolute_error: 9.3535 - val_loss: 1461.2171 - val_mean_absolute_error: 12.7031\n",
            "Epoch 39/100\n",
            "5332/5332 [==============================] - 4s 743us/step - loss: 1861.4546 - mean_absolute_error: 8.9140 - val_loss: 1428.6051 - val_mean_absolute_error: 13.4615\n",
            "Epoch 40/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1513.6846 - mean_absolute_error: 8.7669 - val_loss: 1263.5109 - val_mean_absolute_error: 12.7140\n",
            "Epoch 41/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 1618.7428 - mean_absolute_error: 8.8888 - val_loss: 1186.7256 - val_mean_absolute_error: 12.3739\n",
            "Epoch 42/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1408.1529 - mean_absolute_error: 9.0872 - val_loss: 1122.1428 - val_mean_absolute_error: 12.2658\n",
            "Epoch 43/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1837.7269 - mean_absolute_error: 8.7093 - val_loss: 1137.2103 - val_mean_absolute_error: 12.2066\n",
            "Epoch 44/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1407.3392 - mean_absolute_error: 8.8631 - val_loss: 1120.9952 - val_mean_absolute_error: 12.3441\n",
            "Epoch 45/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1527.5677 - mean_absolute_error: 8.8215 - val_loss: 1136.8738 - val_mean_absolute_error: 12.0560\n",
            "Epoch 46/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1617.6156 - mean_absolute_error: 8.9737 - val_loss: 1127.3141 - val_mean_absolute_error: 12.1746\n",
            "Epoch 47/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 2982.4667 - mean_absolute_error: 9.1822 - val_loss: 7448.7276 - val_mean_absolute_error: 14.0157\n",
            "Epoch 48/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1728.3412 - mean_absolute_error: 9.2846 - val_loss: 1289.8461 - val_mean_absolute_error: 13.4238\n",
            "Epoch 49/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 3038.7624 - mean_absolute_error: 9.0586 - val_loss: 968.5447 - val_mean_absolute_error: 11.4908\n",
            "Epoch 50/100\n",
            "5332/5332 [==============================] - 4s 736us/step - loss: 2659.9441 - mean_absolute_error: 9.3049 - val_loss: 1542.5325 - val_mean_absolute_error: 14.3165\n",
            "Epoch 51/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1297.5642 - mean_absolute_error: 8.8602 - val_loss: 1503.2242 - val_mean_absolute_error: 14.1019\n",
            "Epoch 52/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1661.4435 - mean_absolute_error: 8.7966 - val_loss: 1412.1111 - val_mean_absolute_error: 13.8767\n",
            "Epoch 53/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1432.3660 - mean_absolute_error: 8.7624 - val_loss: 1430.6121 - val_mean_absolute_error: 14.0182\n",
            "Epoch 54/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1149.3803 - mean_absolute_error: 8.5767 - val_loss: 1283.3308 - val_mean_absolute_error: 13.2587\n",
            "Epoch 55/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1011.0365 - mean_absolute_error: 8.5373 - val_loss: 1357.3126 - val_mean_absolute_error: 13.6509\n",
            "Epoch 56/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1314.7556 - mean_absolute_error: 8.5497 - val_loss: 1335.2465 - val_mean_absolute_error: 13.2671\n",
            "Epoch 57/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1068.4556 - mean_absolute_error: 8.4761 - val_loss: 1387.2622 - val_mean_absolute_error: 13.3361\n",
            "Epoch 58/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1681.7082 - mean_absolute_error: 8.6757 - val_loss: 1250.7407 - val_mean_absolute_error: 13.2722\n",
            "Epoch 59/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 2659.9334 - mean_absolute_error: 9.2475 - val_loss: 1232.0559 - val_mean_absolute_error: 12.6882\n",
            "Epoch 60/100\n",
            "5332/5332 [==============================] - 4s 736us/step - loss: 1485.4383 - mean_absolute_error: 8.6924 - val_loss: 1814.4299 - val_mean_absolute_error: 14.0054\n",
            "Epoch 61/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 2007.8172 - mean_absolute_error: 8.9522 - val_loss: 1629.9695 - val_mean_absolute_error: 14.3464\n",
            "Epoch 62/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 2321.7486 - mean_absolute_error: 8.8370 - val_loss: 1868.4563 - val_mean_absolute_error: 15.2426\n",
            "Epoch 63/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 2633.8972 - mean_absolute_error: 8.9948 - val_loss: 1589.3794 - val_mean_absolute_error: 14.1757\n",
            "Epoch 64/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 1956.9037 - mean_absolute_error: 8.7747 - val_loss: 1653.2637 - val_mean_absolute_error: 14.2865\n",
            "Epoch 65/100\n",
            "5332/5332 [==============================] - 4s 744us/step - loss: 1018.0492 - mean_absolute_error: 8.4194 - val_loss: 1609.4044 - val_mean_absolute_error: 14.2757\n",
            "Epoch 66/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1040.8203 - mean_absolute_error: 8.3841 - val_loss: 2042.7703 - val_mean_absolute_error: 15.6567\n",
            "Epoch 67/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1024.6146 - mean_absolute_error: 8.5671 - val_loss: 2025.3463 - val_mean_absolute_error: 15.4294\n",
            "Epoch 68/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1121.6291 - mean_absolute_error: 8.5109 - val_loss: 1706.6069 - val_mean_absolute_error: 14.4412\n",
            "Epoch 69/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 2593.6499 - mean_absolute_error: 8.8372 - val_loss: 1944.5588 - val_mean_absolute_error: 15.1175\n",
            "Epoch 70/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 981.1263 - mean_absolute_error: 8.5224 - val_loss: 1858.4946 - val_mean_absolute_error: 14.7447\n",
            "Epoch 71/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 980.8303 - mean_absolute_error: 8.4327 - val_loss: 1789.6631 - val_mean_absolute_error: 14.7339\n",
            "Epoch 72/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 2137.7733 - mean_absolute_error: 8.8192 - val_loss: 1171.7337 - val_mean_absolute_error: 12.5875\n",
            "Epoch 73/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1530.5646 - mean_absolute_error: 8.7741 - val_loss: 1908.3447 - val_mean_absolute_error: 14.8442\n",
            "Epoch 74/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 2084.9882 - mean_absolute_error: 8.9257 - val_loss: 1827.1080 - val_mean_absolute_error: 15.2169\n",
            "Epoch 75/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1956.9598 - mean_absolute_error: 9.0519 - val_loss: 1412.9184 - val_mean_absolute_error: 13.4893\n",
            "Epoch 76/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1369.1765 - mean_absolute_error: 8.5210 - val_loss: 1501.1471 - val_mean_absolute_error: 13.9769\n",
            "Epoch 77/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1479.3481 - mean_absolute_error: 8.7438 - val_loss: 1277.1838 - val_mean_absolute_error: 13.0382\n",
            "Epoch 78/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 1572.8989 - mean_absolute_error: 8.8199 - val_loss: 1530.7892 - val_mean_absolute_error: 13.7134\n",
            "Epoch 79/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 997.8897 - mean_absolute_error: 8.4713 - val_loss: 1986.6124 - val_mean_absolute_error: 15.0607\n",
            "Epoch 80/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1041.5217 - mean_absolute_error: 8.5141 - val_loss: 1713.5986 - val_mean_absolute_error: 14.6226\n",
            "Epoch 81/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 888.1270 - mean_absolute_error: 8.5049 - val_loss: 1952.4379 - val_mean_absolute_error: 15.1415\n",
            "Epoch 82/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 876.0571 - mean_absolute_error: 8.4383 - val_loss: 2378.4423 - val_mean_absolute_error: 15.9373\n",
            "Epoch 83/100\n",
            "5332/5332 [==============================] - 4s 738us/step - loss: 1126.7143 - mean_absolute_error: 8.5997 - val_loss: 1827.9198 - val_mean_absolute_error: 14.4933\n",
            "Epoch 84/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1192.7288 - mean_absolute_error: 8.4721 - val_loss: 2684.3378 - val_mean_absolute_error: 16.6891\n",
            "Epoch 85/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 934.5651 - mean_absolute_error: 8.6463 - val_loss: 1161.9751 - val_mean_absolute_error: 12.4453\n",
            "Epoch 86/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1100.6262 - mean_absolute_error: 8.5236 - val_loss: 3495.7995 - val_mean_absolute_error: 18.5591\n",
            "Epoch 87/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1197.0344 - mean_absolute_error: 8.5252 - val_loss: 2204.9154 - val_mean_absolute_error: 15.6214\n",
            "Epoch 88/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 1151.2903 - mean_absolute_error: 8.5347 - val_loss: 2361.7338 - val_mean_absolute_error: 16.2343\n",
            "Epoch 89/100\n",
            "5332/5332 [==============================] - 4s 740us/step - loss: 856.8930 - mean_absolute_error: 8.5334 - val_loss: 2062.8459 - val_mean_absolute_error: 15.1967\n",
            "Epoch 90/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 763.8886 - mean_absolute_error: 8.2121 - val_loss: 1608.4204 - val_mean_absolute_error: 13.7052\n",
            "Epoch 91/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1242.2225 - mean_absolute_error: 8.4918 - val_loss: 1665.5246 - val_mean_absolute_error: 14.0160\n",
            "Epoch 92/100\n",
            "5332/5332 [==============================] - 4s 736us/step - loss: 829.1402 - mean_absolute_error: 8.4399 - val_loss: 3158.4792 - val_mean_absolute_error: 17.3606\n",
            "Epoch 93/100\n",
            "5332/5332 [==============================] - 4s 735us/step - loss: 1271.0824 - mean_absolute_error: 8.6047 - val_loss: 3377.5680 - val_mean_absolute_error: 17.9746\n",
            "Epoch 94/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 860.6530 - mean_absolute_error: 8.5521 - val_loss: 1268.0319 - val_mean_absolute_error: 12.3681\n",
            "Epoch 95/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 817.4080 - mean_absolute_error: 8.1856 - val_loss: 3591.3997 - val_mean_absolute_error: 17.9828\n",
            "Epoch 96/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1258.8096 - mean_absolute_error: 8.6571 - val_loss: 3214.4512 - val_mean_absolute_error: 17.1837\n",
            "Epoch 97/100\n",
            "5332/5332 [==============================] - 4s 742us/step - loss: 1086.2474 - mean_absolute_error: 8.5282 - val_loss: 2726.7294 - val_mean_absolute_error: 16.2597\n",
            "Epoch 98/100\n",
            "5332/5332 [==============================] - 4s 739us/step - loss: 1137.5096 - mean_absolute_error: 8.5405 - val_loss: 2713.8402 - val_mean_absolute_error: 16.0894\n",
            "Epoch 99/100\n",
            "5332/5332 [==============================] - 4s 737us/step - loss: 1543.3813 - mean_absolute_error: 8.5400 - val_loss: 5460.2782 - val_mean_absolute_error: 20.5039\n",
            "Epoch 100/100\n",
            "5332/5332 [==============================] - 4s 741us/step - loss: 1807.1122 - mean_absolute_error: 9.1012 - val_loss: 2751.0396 - val_mean_absolute_error: 15.4843\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}